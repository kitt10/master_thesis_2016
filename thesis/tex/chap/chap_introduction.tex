\chapter{Introduction} \label{chapter:01:introduction}

The thesis must clearly state its theme, hypotheses and/or goals (sometimes called “the research question(s)”), and provide sufficient background information to enable a non-specialist researcher to understand them. It must contain a thorough review of relevant literature, perhaps in a separate chapter.

previously unsolved problems

name machine learning applications

whatever is possible

1-2 pages intro

\newpage
\section{Problem Formulation}
1 page

\newpage
\section{Classification} \label{sec:soa_other_classifiers}
Classification is one of the most widely used areas of machine learning. The idea is based on training a model on a set of data by setting some model parameters. A wide range of classification methods, differing one from each other in their mathematical backgrounds, are provided nowadays, however, the classification procedure follows a conventional line:

\begin{enumerate}
\item model initialization;
\item learning process (using data A);
\item prediction (using never-seen data B).
\end{enumerate}

To fit a classifier to a problem, one needs to define a problem data structure. Data consists of samples and discrete targets, often called classes. The samples are sooner or later converted into so called feature vectors of a fixed length. The length of feature vectors usually determines an input of a chosen classifier and the number of classes sets an output.

Basically, any kind of problem, ordinarily being solved by a human, can be transformed to a classification task for an artificial agent, if we define classes and find a numerical representation.

\subsection*{Overview of Classification Methods} \label{ssec:other_classification_methods}
The data samples usually consist of multiple features and the classes are linearly inseparable in most of the cases. The goal is to separate the classes in a high-dimensional space (illustrated in \cref{img:classification_problem_formulation}).

\begin{figure}[H]
  \centering
  \includegraphics[width=0.4\textwidth]{classification_problem_formulation.png}
  \caption{Formulation of a classification problem.}
  \label{img:classification_problem_formulation}
\end{figure}

\textit{Support Vector Machines} (\textit{SVMs}) construct a set of hyperplanes in the high dimensional space to separate the classes. The position of the hyperplanes is based on so-called support vectors, which define distances to the nearest training-data points. Using the support vectors, a hyperplane with the largest margin between two classes is created and used for classification. The linear inseparability is solved by a kernel trick, which maps the original finite-dimensional space into a much higher-dimensional space.

The \textit{k-Nearest Neighbours} (\textit{k-NN}) algorithm uses a more straightforward way to classify samples into classes. Instead of finding the separation planes, this approach computes distances from the classified sample to $ k $ nearest samples of the training data. Then the class is determined by the majority vote of those known samples. This approach skips the training process, however, the prediction is computationally expensive.

The \textit{Random Forest} (\textit{RF}) approach is based on decision trees, which learn simple decision rules inferred from the data features. Decision trees are known for having troubles with over-fitting, therefore the random forest uses many decision trees and finds a classification result by averaging their outputs (bagging).

Additionaly, the \textit{Naive Bayes} approach is based on statistical analysis and uses a likelihood to predict classes. Each of those methods has some adventages and disadvantages on a particular type of data and its distribution. For instance, \textit{SVMs} are a powerful tool for binary problems with an outlier free distributions. For a multiclass data, where many outliers are expected, one should choose Random Forest, however, the decision trees usually need a longer classification time.

To summarize, a best classification method has not been prooved yet. However, \textit{neural networks} (\textit{NN}) are being used for more and more fields nowadays.  

\subsection*{Feedforward Neural Networks} \label{ssec:intro_to_nn}

perceptron, MLP, neural networks from the beginning, network types, principles its usage for classification


\section{Pruning Algorithms} \label{sec:soa_pruning_algorithms}

based on the paper Pruning Algorithms - A Survey: a summary of what has been already done, principles 
1-2 pages

\section{Terrain Classification for Legged Robots} \label{sec:soa_terrain_classification}

based on the literature : a summary of what has been already done in terrain classification, summary of different methods (visual, laser, haptic, proprioception, ...)

5-8 pages 


\section{Relation to the State of the Art}
Motivation and Research Questions
motivation for using proprioception sensing
motivation for using a neural net as a classifier

in this section you can relate your work to the existing state of the art methods and tell why you have chosen those and what is your contribution to the state of the art

1/2 page

\section{Hypotheses}

1/2 page

\newpage
\section{Master Thesis Objectives} \label{sec:goals}

\section{Thesis Outline}

1/2 page

